---
title: "An√°lise Tem√°tica de PDF com Identifica√ß√£o de Categorias"
author: "Seu Nome"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: flatly
    df_print: paged
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
# Aumentar o limite de upload para 30MB
options(shiny.maxRequestSize = 30*1024^2)  # 30MB
# Carregar todas as bibliotecas necess√°rias
library(shiny)
library(pdftools)
library(tm)
library(wordcloud)
library(ggplot2)
library(RColorBrewer)
library(tidytext)    # Para tokeniza√ß√£o
library(dplyr)       # Para manipula√ß√£o de dados
library(stringr)     # Para fun√ß√µes de string
library(tidyr)       # Para manipula√ß√£o de dados tidyverse
library(topicmodels) # Para modelagem de t√≥picos
library(stm)         # Para modelagem de t√≥picos estruturais
library(tidygraph)   # Para visualiza√ß√£o de redes
library(ggraph)      # Para visualiza√ß√£o de redes
library(igraph)      # Para an√°lise de redes
library(networkD3)   # Para visualiza√ß√£o interativa de redes
```

## üì• Upload e An√°lise do Arquivo PDF

```{r ui-upload, echo=FALSE}
fluidRow(
  column(6, 
    fileInput("arquivo_pdf", "Escolha um arquivo PDF", 
              accept = ".pdf",
              buttonLabel = "Procurar...")
  ),
  column(6,
    actionButton("analisar", "Analisar Documento", 
                icon = icon("play"),
                class = "btn-primary",
                style = "margin-top: 25px;")
  )
)
```

```{r server-analise, echo=FALSE}
# Vari√°veis reativas para controlar o estado da an√°lise
analise_realizada <- reactiveValues(valor = FALSE)

# Observer para o bot√£o de an√°lise
observeEvent(input$analisar, {
  req(input$arquivo_pdf)
  analise_realizada$valor <- TRUE
})

# Texto extra√≠do do PDF
output_text <- reactive({
  req(input$arquivo_pdf)
  req(analise_realizada$valor)
  # Extrair todas as p√°ginas do PDF e manter a formata√ß√£o por p√°gina
  texto_pdf <- pdftools::pdf_text(input$arquivo_pdf$datapath)
  return(texto_pdf)  # Retorna um vetor com cada p√°gina como um elemento
})

# Texto preparado para processamento
texto_preparado <- reactive({
  req(output_text())
  
  # Combinar todas as p√°ginas em um √∫nico texto
  texto_completo <- paste(output_text(), collapse = " ")
  
  # Remover caracteres especiais, n√∫meros e pontua√ß√£o
  texto_limpo <- texto_completo %>%
    str_to_lower() %>%
    str_replace_all("[[:punct:]]", " ") %>%
    str_replace_all("[[:digit:]]", " ") %>%
    str_replace_all("\\s+", " ") %>%
    str_trim()
  
  return(texto_limpo)
})

# Gera√ß√£o do corpus para an√°lise de t√≥picos
corpus_dtm <- reactive({
  req(texto_preparado())
  
  # Criar corpus
  corpus <- VCorpus(VectorSource(texto_preparado()))
  
  # Pr√©-processamento
  corpus <- tm_map(corpus, content_transformer(tolower))
  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, removeNumbers)
  corpus <- tm_map(corpus, removeWords, stopwords("portuguese"))
  corpus <- tm_map(corpus, stripWhitespace)
  
  # Criar matriz documento-termo
  dtm <- DocumentTermMatrix(corpus)
  
  # Remover termos raros (que aparecem em menos de 1% dos documentos)
  dtm_filtrado <- removeSparseTerms(dtm, 0.99)
  
  return(list(corpus = corpus, dtm = dtm_filtrado))
})

# Fun√ß√£o para identificar t√≥picos usando LDA
identificar_topicos <- reactive({
  req(corpus_dtm())
  
  dtm <- corpus_dtm()$dtm
  
  # Verificar se h√° termos suficientes
  if (ncol(dtm) < 10) {
    return(NULL)
  }
  
  # Ajustar o n√∫mero de t√≥picos com base no tamanho do documento
  # Sugest√£o: usar entre 3 e 10 t√≥picos para um documento t√≠pico
  num_topicos <- min(10, max(3, ncol(dtm) %/% 50))
  
  tryCatch({
    # Aplicar LDA para modelagem de t√≥picos
    modelo_lda <- LDA(dtm, k = num_topicos, control = list(seed = 123))
    
    # Extrair os principais termos por t√≥pico
    beta <- tidy(modelo_lda, matrix = "beta")
    
    # Extrair os 10 principais termos para cada t√≥pico
    top_termos <- beta %>%
      group_by(topic) %>%
      top_n(10, beta) %>%
      arrange(topic, -beta) %>%
      mutate(topic_name = paste("T√≥pico", topic)) %>%
      ungroup()
    
    # Extrair a distribui√ß√£o de t√≥picos no documento
    gamma <- tidy(modelo_lda, matrix = "gamma")
    
    # Calcular a probabilidade m√©dia de cada t√≥pico
    topico_prob <- gamma %>%
      group_by(topic) %>%
      summarise(probabilidade = mean(gamma)) %>%
      arrange(desc(probabilidade))
    
    return(list(
      modelo = modelo_lda,
      top_termos = top_termos,
      topico_prob = topico_prob
    ))
  }, error = function(e) {
    # Em caso de erro na an√°lise de t√≥picos
    return(NULL)
  })
})

# Fun√ß√£o para avaliar a qualidade dos t√≥picos (alternativa simples ao ldatuning)
avaliar_topicos <- reactive({
  req(corpus_dtm())
  
  dtm <- corpus_dtm()$dtm
  
  # Verificar se h√° termos suficientes
  if (ncol(dtm) < 10) {
    return(NULL)
  }
  
  # Definir uma sequ√™ncia de n√∫meros de t√≥picos para avaliar
  k_values <- seq(2, min(20, ncol(dtm) %/% 10), by = 1)
  
  # Inicializar vetores para armazenar resultados
  perplexities <- numeric(length(k_values))
  coherence <- numeric(length(k_values))
  
  # Avaliar cada n√∫mero de t√≥picos
  for (i in seq_along(k_values)) {
    k <- k_values[i]
    
    # Treinar modelo LDA
    modelo_lda <- LDA(dtm, k = k, control = list(seed = 123))
    
    # Calcular perplexidade (menor √© melhor)
    perplexities[i] <- perplexity(modelo_lda)
    
    # Calcular uma medida simples de coer√™ncia baseada nos principais termos
    beta <- tidy(modelo_lda, matrix = "beta")
    top_terms_by_topic <- beta %>%
      group_by(topic) %>%
      top_n(10, beta) %>%
      arrange(topic, -beta)
    
    # Uma medida simples de coer√™ncia √© a m√©dia das probabilidades beta dos principais termos
    # (maior √© melhor)
    coherence[i] <- mean(top_terms_by_topic$beta)
  }
  
  # Criar um dataframe com os resultados
  resultados <- data.frame(
    k = k_values,
    perplexidade = perplexities,
    coerencia = coherence
  )
  
  return(resultados)
})

# Identifica√ß√£o de categorias e temas recorrentes
identificar_categorias <- reactive({
  req(corpus_dtm())
  
  corpus <- corpus_dtm()$corpus
  dtm <- corpus_dtm()$dtm
  
  # Extrair os termos mais frequentes
  freq_termos <- colSums(as.matrix(dtm))
  termos_ordenados <- sort(freq_termos, decreasing = TRUE)
  
  # Selecionar os 100 termos mais frequentes
  top_termos <- data.frame(
    termo = names(termos_ordenados)[1:min(100, length(termos_ordenados))],
    frequencia = termos_ordenados[1:min(100, length(termos_ordenados))],
    stringsAsFactors = FALSE
  )
  
  # Criar uma matriz de co-ocorr√™ncia para an√°lise de rede
  if (ncol(dtm) > 5) {
    # Converter para matriz
    matriz_dtm <- as.matrix(dtm)
    
    # Calcular a matriz de co-ocorr√™ncia
    coocorrencia <- t(matriz_dtm) %*% matriz_dtm
    
    # Transformar em matriz de adjac√™ncia para an√°lise de rede
    matriz_adj <- coocorrencia
    diag(matriz_adj) <- 0
    
    # Limitar a 30 termos mais frequentes para a rede
    termos_rede <- names(termos_ordenados)[1:min(30, length(termos_ordenados))]
    matriz_rede <- matriz_adj[termos_rede, termos_rede]
    
    # Criar grafo
    grafo <- graph_from_adjacency_matrix(
      matriz_rede,
      mode = "undirected",
      weighted = TRUE
    )
    
    # Calcular centralidade
    centralidade <- data.frame(
      termo = V(grafo)$name,
      grau = degree(grafo),
      intermediacao = betweenness(grafo),
      proximidade = closeness(grafo),
      stringsAsFactors = FALSE
    )
    
    # Ordenar por grau
    centralidade <- centralidade %>%
      arrange(desc(grau))
    
    # Detec√ß√£o de comunidades (categorias)
    comunidades <- cluster_louvain(grafo)
    
    # Extrair os grupos
    grupos <- data.frame(
      termo = V(grafo)$name,
      grupo = membership(comunidades),
      stringsAsFactors = FALSE
    )
    
    # Agrupar por grupo e extrair termos representativos
    categorias <- grupos %>%
      group_by(grupo) %>%
      summarise(
        termos = paste(termo, collapse = ", "),
        num_termos = n()
      ) %>%
      arrange(desc(num_termos))
    
    return(list(
      top_termos = top_termos,
      grafo = grafo,
      centralidade = centralidade,
      categorias = categorias,
      grupos = grupos
    ))
  } else {
    # Caso n√£o haja termos suficientes para an√°lise de rede
    return(list(
      top_termos = top_termos,
      grafo = NULL,
      centralidade = NULL,
      categorias = NULL,
      grupos = NULL
    ))
  }
})

# Preparar dados para visualiza√ß√£o de rede
preparar_rede <- reactive({
  req(identificar_categorias()$grafo)
  
  grafo <- identificar_categorias()$grafo
  grupos <- identificar_categorias()$grupos
  
  # Adicionar informa√ß√µes de grupo aos v√©rtices
  V(grafo)$grupo <- grupos$grupo[match(V(grafo)$name, grupos$termo)]
  
  # Preparar dados para visualiza√ß√£o D3
  rede_d3 <- igraph_to_networkD3(grafo)
  
  # Adicionar grupos
  rede_d3$nodes$group <- grupos$grupo[match(rede_d3$nodes$name, grupos$termo)]
  
  return(rede_d3)
})
```

## üìä Resultados da An√°lise

```{r ui-resultados, echo=FALSE}
# Mostrar os resultados apenas quando a an√°lise for executada
conditionalPanel(
  condition = "input.analisar",
  tabsetPanel(
    tabPanel("Texto Extra√≠do", 
      h4("Texto do PDF (por p√°gina):"),
      uiOutput("paginas_pdf")
    ),
    tabPanel("An√°lise de T√≥picos",
      h4("Modelagem de T√≥picos (LDA)"),
      sliderInput("num_topicos", "N√∫mero de t√≥picos:", 
                  min = 2, max = 20, value = 5, step = 1),
      uiOutput("info_topicos"),
      plotOutput("grafico_topicos"),
      h4("Principais Termos por T√≥pico"),
      dataTableOutput("tabela_topicos"),
      h4("Avalia√ß√£o de N√∫mero de T√≥picos"),
      plotOutput("grafico_avaliacao_topicos")
    ),
    tabPanel("An√°lise de Categorias",
      h4("Categorias Tem√°ticas Identificadas"),
      uiOutput("info_categorias"),
      dataTableOutput("tabela_categorias"),
      h4("Visualiza√ß√£o de Rede de Termos"),
      forceNetworkOutput("rede_termos", height = "500px"),
      h4("Termos mais Centrais"),
      dataTableOutput("tabela_centralidade")
    ),
    tabPanel("Nuvem de Palavras",
      h4("Visualiza√ß√£o dos Termos Mais Frequentes"),
      plotOutput("nuvem_palavras", height = "500px")
    )
  )
)
```

```{r server-resultados, echo=FALSE}
# Mostrar texto extra√≠do p√°gina por p√°gina com formata√ß√£o melhorada
output$paginas_pdf <- renderUI({
  req(output_text())
  
  # Criar uma lista de elementos UI para cada p√°gina
  paginas <- lapply(seq_along(output_text()), function(i) {
    # Para cada p√°gina, criar um painel
    wellPanel(
      h5(paste("P√°gina", i)),
      tags$pre(
        style = "white-space: pre-wrap; word-wrap: break-word; max-height: 300px; overflow-y: auto;",
        output_text()[i]
      )
    )
  })
  
  # Combinar todos os elementos em um √∫nico objeto UI
  do.call(tagList, paginas)
})

# Modelo LDA com n√∫mero de t√≥picos definido pelo usu√°rio
modelo_lda_dinamico <- reactive({
  req(corpus_dtm())
  req(input$num_topicos)
  
  dtm <- corpus_dtm()$dtm
  
  # Verificar se h√° termos suficientes
  if (ncol(dtm) < 5) {
    return(NULL)
  }
  
  # Aplicar LDA para modelagem de t√≥picos
  tryCatch({
    modelo_lda <- LDA(dtm, k = input$num_topicos, control = list(seed = 123))
    return(modelo_lda)
  }, error = function(e) {
    # Em caso de erro na an√°lise de t√≥picos
    return(NULL)
  })
})

# Informa√ß√µes sobre t√≥picos
output$info_topicos <- renderUI({
  req(modelo_lda_dinamico())
  
  modelo <- modelo_lda_dinamico()
  
  if (is.null(modelo)) {
    return(div(
      class = "alert alert-warning",
      "N√£o foi poss√≠vel identificar t√≥picos suficientes no documento. Tente um documento maior ou com mais conte√∫do textual."
    ))
  }
  
  # Extrair a distribui√ß√£o de t√≥picos
  gamma <- tidy(modelo, matrix = "gamma")
  
  # Calcular a probabilidade m√©dia de cada t√≥pico
  topico_prob <- gamma %>%
    group_by(topic) %>%
    summarise(probabilidade = mean(gamma)) %>%
    arrange(desc(probabilidade))
  
  div(
    class = "well",
    h5("Resumo dos T√≥picos Identificados:"),
    p("Foram identificados", input$num_topicos, "t√≥picos principais no documento."),
    p("A distribui√ß√£o de probabilidade dos t√≥picos √©:"),
    div(
      style = "display: flex; flex-wrap: wrap; gap: 10px;",
      lapply(1:nrow(topico_prob), function(i) {
        span(
          style = paste0(
            "padding: 8px; border-radius: 4px; margin-bottom: 5px; ",
            "background-color: ", colorRampPalette(brewer.pal(8, "Set2"))(nrow(topico_prob))[i]
          ),
          paste0("T√≥pico ", topico_prob$topic[i], ": ", round(topico_prob$probabilidade[i] * 100, 1), "%")
        )
      })
    )
  )
})

# Gr√°fico de avalia√ß√£o de t√≥picos
output$grafico_avaliacao_topicos <- renderPlot({
  req(avaliar_topicos())
  
  resultados <- avaliar_topicos()
  
  # Criar um gr√°fico para visualizar a perplexidade e coer√™ncia
  p1 <- ggplot(resultados, aes(x = k, y = perplexidade)) +
    geom_line() +
    geom_point() +
    labs(title = "Perplexidade (menor √© melhor)",
         x = "N√∫mero de t√≥picos (k)",
         y = "Perplexidade") +
    theme_minimal()
  
  p2 <- ggplot(resultados, aes(x = k, y = coerencia)) +
    geom_line() +
    geom_point() +
    labs(title = "Coer√™ncia (maior √© melhor)",
         x = "N√∫mero de t√≥picos (k)",
         y = "Coer√™ncia") +
    theme_minimal()
  
  # Mostrar os dois gr√°ficos lado a lado
  gridExtra::grid.arrange(p1, p2, ncol = 2)
})

# Gr√°fico de t√≥picos
output$grafico_topicos <- renderPlot({
  req(modelo_lda_dinamico())
  
  modelo <- modelo_lda_dinamico()
  
  if (is.null(modelo)) {
    # Gr√°fico vazio se n√£o houver t√≥picos
    ggplot() + 
      annotate("text", x = 0.5, y = 0.5, label = "Sem t√≥picos para exibir") +
      theme_void() +
      xlim(0, 1) + ylim(0, 1)
  } else {
    # Extrair os termos mais importantes para cada t√≥pico
    beta <- tidy(modelo, matrix = "beta")
    
    # Gr√°fico de barras dos termos mais importantes para cada t√≥pico
    beta %>%
      group_by(topic) %>%
      top_n(10, beta) %>%
      ungroup() %>%
      mutate(
        term = reorder_within(term, beta, topic),
        topic_name = paste("T√≥pico", topic)
      ) %>%
      ggplot(aes(term, beta, fill = factor(topic))) +
      geom_col(show.legend = FALSE) +
      facet_wrap(~ topic_name, scales = "free_y") +
      coord_flip() +
      scale_x_reordered() +
      labs(title = "Principais Termos por T√≥pico",
           x = "Termo", 
           y = "Import√¢ncia (Beta)") +
      theme_minimal() +
      scale_fill_brewer(palette = "Set2")
  }
})

# Tabela de t√≥picos
output$tabela_topicos <- renderDataTable({
  req(modelo_lda_dinamico())
  
  modelo <- modelo_lda_dinamico()
  
  if (is.null(modelo)) {
    return(NULL)
  }
  
  # Extrair termos e distribui√ß√£o
  beta <- tidy(modelo, matrix = "beta")
  gamma <- tidy(modelo, matrix = "gamma")
  
  # Obter os principais termos por t√≥pico
  top_termos <- beta %>%
    group_by(topic) %>%
    top_n(10, beta) %>%
    arrange(topic, -beta) %>%
    group_by(topic) %>%
    summarise(termos = paste(term, collapse = ", "))
  
  # Calcular a probabilidade m√©dia de cada t√≥pico
  topico_prob <- gamma %>%
    group_by(topic) %>%
    summarise(probabilidade = mean(gamma)) %>%
    arrange(desc(probabilidade))
  
  # Juntar os dados
  resultado <- top_termos %>%
    left_join(topico_prob, by = "topic") %>%
    mutate(
      topic_name = paste("T√≥pico", topic),
      probabilidade = paste0(round(probabilidade * 100, 1), "%")
    ) %>%
    select(
      "T√≥pico" = topic_name,
      "Probabilidade" = probabilidade,
      "Principais Termos" = termos
    )
  
  return(resultado)
}, options = list(pageLength = 5, dom = 'tip'))

# Informa√ß√µes sobre categorias
output$info_categorias <- renderUI({
  req(identificar_categorias())
  
  categorias <- identificar_categorias()
  
  if (is.null(categorias$categorias)) {
    return(div(
      class = "alert alert-warning",
      "N√£o foi poss√≠vel identificar categorias tem√°ticas no documento. Tente um documento maior ou com mais conte√∫do textual."
    ))
  }
  
  # Informa√ß√µes sobre as categorias identificadas
  div(
    class = "well",
    h5("Resumo das Categorias Tem√°ticas:"),
    p("Foram identificadas", nrow(categorias$categorias), "categorias tem√°ticas no documento."),
    p("As categorias s√£o definidas por grupos de palavras que tendem a ocorrer juntas no texto.")
  )
})

# Tabela de categorias
output$tabela_categorias <- renderDataTable({
  req(identificar_categorias())
  
  categorias <- identificar_categorias()
  
  if (is.null(categorias$categorias)) {
    return(NULL)
  }
  
  # Preparar dados para a tabela
  categorias$categorias %>%
    mutate(
      Categoria = paste("Categoria", grupo),
      `N√∫mero de Termos` = num_termos,
      `Termos Representativos` = termos
    ) %>%
    select(Categoria, `N√∫mero de Termos`, `Termos Representativos`)
  
}, options = list(pageLength = 5, dom = 'tip'))

# Rede de termos
output$rede_termos <- renderForceNetwork({
  req(preparar_rede())
  
  rede_d3 <- preparar_rede()
  
  # Configurar a visualiza√ß√£o
  forceNetwork(
    Links = rede_d3$links, 
    Nodes = rede_d3$nodes,
    Source = "source", 
    Target = "target", 
    NodeID = "name",
    Group = "group", 
    opacity = 0.8,
    linkDistance = 100,
    charge = -300,
    fontSize = 14,
    linkWidth = JS("function(d) { return Math.sqrt(d.value); }"),
    colourScale = JS("d3.scaleOrdinal(d3.schemeCategory10);")
  )
})

# Tabela de centralidade
output$tabela_centralidade <- renderDataTable({
  req(identificar_categorias()$centralidade)
  
  centralidade <- identificar_categorias()$centralidade
  
  if (is.null(centralidade)) {
    return(NULL)
  }
  
  # Preparar dados para a tabela
  centralidade %>%
    head(20) %>%
    mutate(
      `Intermedia√ß√£o` = round(intermediacao, 2),
      `Proximidade` = round(proximidade, 5)
    ) %>%
    select(
      "Termo" = termo,
      "Grau" = grau,
      "Intermedia√ß√£o",
      "Proximidade"
    )
  
}, options = list(pageLength = 10, dom = 'tip'))

# Nuvem de palavras
output$nuvem_palavras <- renderPlot({
  req(identificar_categorias()$top_termos)
  
  top_termos <- identificar_categorias()$top_termos
  
  if (nrow(top_termos) > 0) {
    set.seed(123)  # Para reprodutibilidade
    tryCatch({
      wordcloud(
        words = top_termos$termo,
        freq = top_termos$frequencia,
        min.freq = 1,
        max.words = 100,
        random.order = FALSE,
        rot.per = 0.35,
        colors = brewer.pal(8, "Dark2"),
        scale = c(4, 0.5)
      )
    }, error = function(e) {
      # Em caso de erro, mostrar mensagem
      plot(0, 0, type = "n", axes = FALSE, xlab = "", ylab = "")
      text(0, 0, paste("Erro ao gerar nuvem:", e$message), cex = 1.2)
    })
  } else {
    # Mensagem para quando n√£o h√° palavras suficientes
    plot(0, 0, type = "n", axes = FALSE, xlab = "", ylab = "")
    text(0, 0, "N√£o h√° palavras suficientes para gerar a nuvem", cex = 1.5)
  }
})
```

## üìù Como usar

1. Clique no bot√£o "Procurar..." para selecionar um arquivo PDF
2. Clique no bot√£o "Analisar Documento" para processar o texto
3. Explore os resultados nas diferentes abas:
   - **Texto Extra√≠do**: Veja o conte√∫do do PDF, organizado por p√°gina
   - **An√°lise de T√≥picos**: 
     - Defina o n√∫mero de t√≥picos desejado usando o controle deslizante
     - Visualize os principais t√≥picos identificados no documento
     - Veja os termos mais relevantes para cada t√≥pico
     - Analise m√©tricas de avalia√ß√£o para escolher o n√∫mero ideal de t√≥picos
   - **An√°lise de Categorias**: 
     - Explore as categorias tem√°ticas identificadas automaticamente
     - Visualize a rede de termos para entender as rela√ß√µes
     - Analise os termos mais centrais no documento
   - **Nuvem de Palavras**: 
     - Veja uma representa√ß√£o visual dos termos mais frequentes

### Sobre a an√°lise de t√≥picos:

A an√°lise de t√≥picos utiliza o algoritmo LDA (Latent Dirichlet Allocation) para identificar temas latentes no documento, agrupando palavras que tendem a ocorrer juntas. Cada t√≥pico √© representado por uma distribui√ß√£o de probabilidade sobre as palavras, e cada documento √© representado como uma mistura de t√≥picos.

### Sobre a an√°lise de categorias:

A an√°lise de categorias utiliza t√©cnicas de an√°lise de redes para identificar grupos de palavras que est√£o fortemente relacionadas entre si. Palavras que frequentemente ocorrem juntas ou em contextos similares s√£o agrupadas em comunidades (categorias tem√°ticas).

### M√©tricas de avalia√ß√£o de t√≥picos:

- **Perplexidade**: Uma medida da qualidade do modelo - valores mais baixos indicam melhor ajuste.
- **Coer√™ncia**: Uma medida de qu√£o coerentes s√£o os t√≥picos - valores mais altos indicam t√≥picos mais interpret√°veis.

### M√©tricas de centralidade:

- **Grau**: N√∫mero de conex√µes que um termo possui com outros termos
- **Intermedia√ß√£o**: Mede o quanto um termo serve como ponte entre outros termos
- **Proximidade**: Mede o qu√£o pr√≥ximo um termo est√° de todos os outros termos da rede